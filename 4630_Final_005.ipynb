{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2QELq5Ig6MoT",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "import os\n",
        "import shutil\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader, random_split, Dataset\n",
        "from torchvision import datasets, models, transforms\n",
        "import torch.optim as optim\n",
        "from torchvision.models import resnet50, ResNet50_Weights\n",
        "from tqdm import tqdm\n",
        "from collections import Counter\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import shutil\n",
        "import getpass\n",
        "import nbformat\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import random\n",
        "from PIL import Image\n",
        "from sklearn.metrics import accuracy_score, classification_report\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Download latest version of the dataset\n",
        "path = kagglehub.dataset_download('obulisainaren/multi-cancer')\n",
        "\n",
        "print('Path to dataset files:', path)"
      ],
      "metadata": {
        "id": "_kJynV8K-8WG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Path check\n",
        "dataset_path = os.path.join(path, 'Multi Cancer', 'Multi Cancer')\n",
        "print('Using dataset_path:', dataset_path)\n",
        "print(os.listdir(dataset_path))\n"
      ],
      "metadata": {
        "id": "stffdth1u1VI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Lists all cancer types\n",
        "print(os.listdir(dataset_path))\n",
        "classes_to_use = ['Cervical Cancer', 'Oral Cancer', 'Kidney Cancer', 'Breast Cancer', 'Lymphoma', 'Brain Cancer'] #Ignore ALL and Lung and Colon Cancer"
      ],
      "metadata": {
        "id": "xu_QS2-c_n9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Download ResNet50 model\n",
        "model = resnet50(weights=ResNet50_Weights.DEFAULT)"
      ],
      "metadata": {
        "id": "ayvIiEL3URGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Paths and device check\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "if device.type == 'cuda':\n",
        "    print('GPU:', torch.cuda.get_device_name(0))\n",
        "    print('Total GPU memory:', round(torch.cuda.get_device_properties(0).total_memory / 1e9, 2), 'GB')\n",
        "\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "transform_eval = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "\n",
        "# Collect all subfolders as classes\n",
        "all_subfolders = []\n",
        "for main_class in os.listdir(dataset_path):\n",
        "    main_path = os.path.join(dataset_path, main_class)\n",
        "    if os.path.isdir(main_path):\n",
        "        for sub_class in os.listdir(main_path):\n",
        "            sub_path = os.path.join(main_path, sub_class)\n",
        "            if os.path.isdir(sub_path):\n",
        "                all_subfolders.append(sub_path)\n",
        "\n",
        "# ap subfolder paths to class indices and create samples list\n",
        "samples = []\n",
        "class_to_idx = {}\n",
        "for idx, subfolder_path in enumerate(all_subfolders):\n",
        "    class_name = os.path.basename(subfolder_path)\n",
        "    class_to_idx[class_name] = idx\n",
        "    for fname in os.listdir(subfolder_path):\n",
        "        if fname.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "            samples.append((os.path.join(subfolder_path, fname), idx))\n",
        "\n",
        "print('Detected classes:', list(class_to_idx.keys()))\n",
        "print('Total images:', len(samples))\n",
        "\n",
        "\n",
        "#Dataset to deal with nested folders\n",
        "class NestedImageDataset(Dataset):\n",
        "    def __init__(self, samples, transform=None):\n",
        "        self.samples = samples\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path, label = self.samples[idx]\n",
        "        image = Image.open(path).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "full_dataset = NestedImageDataset(samples, transform=transform_train)\n",
        "\n",
        "#Train/Test/Val Split\n",
        "total_size = len(full_dataset)\n",
        "test_size = int(0.1 * total_size)\n",
        "val_size = int(0.1 * total_size)\n",
        "train_size = total_size - val_size - test_size\n",
        "\n",
        "generator = torch.Generator().manual_seed(42)\n",
        "train_dataset, val_dataset, test_dataset = random_split(\n",
        "    full_dataset, [train_size, val_size, test_size], generator=generator\n",
        ")\n",
        "\n",
        "#Evaluation transforms\n",
        "val_dataset.dataset.transform = transform_eval\n",
        "test_dataset.dataset.transform = transform_eval\n",
        "\n",
        "print(f'Train size: {len(train_dataset)}, Val size: {len(val_dataset)}, Test size: {len(test_dataset)}')\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=4, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4, pin_memory=True)\n",
        "\n",
        "\n",
        "model = resnet50(weights=ResNet50_Weights.DEFAULT)        #Model\n",
        "num_classes = len(class_to_idx)\n",
        "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "\n",
        "#Training\n",
        "epochs = 25\n",
        "best_val_acc = 0.0\n",
        "checkpoint_dir = '/content/checkpoints'\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs} [Training]', leave=False)\n",
        "\n",
        "    for images, labels in pbar:\n",
        "        images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        with torch.cuda.amp.autocast():\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        pbar.set_postfix({'Batch Loss': loss.item(),\n",
        "                          'GPU Mem (GB)': round(torch.cuda.memory_allocated(0)/1e9, 2)})\n",
        "\n",
        "\n",
        "    #Validation\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
        "            with torch.cuda.amp.autocast():\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "                _, predicted = outputs.max(1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "    val_acc = 100 * correct / total\n",
        "    print(f'\\nEpoch {epoch+1}/{epochs} Summary:')\n",
        "    print(f'  Train Loss: {total_loss/len(train_loader):.4f}')\n",
        "    print(f'  Val Loss:   {val_loss/len(val_loader):.4f}')\n",
        "    print(f'  Val Acc:    {val_acc:.2f}%')\n",
        "\n",
        "    #Saves checkpoints if they improve\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        checkpoint_path = os.path.join(checkpoint_dir, f'best_model_epoch{epoch+1}.pt')\n",
        "        torch.save(model.state_dict(), checkpoint_path)\n",
        "        print(f'  New best: {checkpoint_path}')\n",
        "\n",
        "    if device.type == 'cuda':\n",
        "        print(f'  GPU Memory Allocated: {round(torch.cuda.memory_allocated(0)/1e9,2)} GB')\n",
        "        print(f'  GPU Memory Cached:    {round(torch.cuda.memory_reserved(0)/1e9,2)} GB')\n",
        "    print('='*50)\n",
        "\n",
        "print('Training complete.')\n",
        "\n",
        "#Test Evaluation\n",
        "print('\\nEvaluating on full test set...')\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for images, labels in tqdm(test_loader, desc='Testing'):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        with torch.cuda.amp.autocast():\n",
        "            outputs = model(images)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Per-class metrics\n",
        "print('\\nPer-class metrics:')\n",
        "print(classification_report(all_labels, all_preds, target_names=list(class_to_idx.keys())))\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "print('\\nConfusion Matrix:\\n', cm)"
      ],
      "metadata": {
        "id": "bqAmd4E24-h0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Initialization (For if you'd like to try this out yourself the model best_model_epoch5.pt in the repo)\n",
        "#Only run this code if you DON'T want to train your own model and would rather use the pretrained model\n",
        "\n",
        "#Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#Model Initialization\n",
        "num_classes = 26  # number of classes in your trained model\n",
        "model = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
        "model.fc = nn.Linear(model.fc.in_features, num_classes)  # number of classes\n",
        "model = model.to(device)\n",
        "\n",
        "#Load trained weights\n",
        "BEST_MODEL = \"/content/checkpoints/best_model_epoch5.pt\"  # Download the model from the repo and paste the path here\n",
        "model.load_state_dict(torch.load(BEST_MODEL, map_location=device))\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "h7Fl-sNMBIlM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()  # ensure evaluation mode\n",
        "\n",
        "all_labels = []\n",
        "all_preds = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in val_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        with torch.cuda.amp.autocast():\n",
        "            outputs = model(images)\n",
        "            _, predicted = outputs.max(1)\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "        all_preds.extend(predicted.cpu().numpy())\n",
        "\n",
        "# Overall accuracy\n",
        "overall_acc = accuracy_score(all_labels, all_preds)\n",
        "print(f'Overall Accuracy: {overall_acc*100:.2f}%\\n')\n",
        "\n",
        "# Per-class precision, recall, F1-score\n",
        "print('Per-class metrics:\\n')\n",
        "target_names = list(class_to_idx.keys())  # ensure correct class names\n",
        "print(classification_report(\n",
        "    all_labels, all_preds,\n",
        "    target_names=target_names,\n",
        "    digits=4  # show 4 decimal places\n",
        "))"
      ],
      "metadata": {
        "id": "9aGWw3iNHosk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Ensure the model is in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "all_labels = []\n",
        "all_preds = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in val_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        with torch.cuda.amp.autocast():\n",
        "            outputs = model(images)\n",
        "            _, predicted = outputs.max(1)\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "        all_preds.extend(predicted.cpu().numpy())\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]  # normalize\n",
        "\n",
        "# Plot matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Blues',\n",
        "            xticklabels=list(class_to_idx.keys()),\n",
        "            yticklabels=list(class_to_idx.keys()))\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Normalized Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NeMvC10zHw-5",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_random_images(subset, model, device, num_images=20, transform=None):    #Randomly chooses 20 images from a dataset and classifies them (proof of concept)\n",
        "\n",
        "    import random\n",
        "    from PIL import Image\n",
        "    from torchvision import transforms\n",
        "\n",
        "    model.eval()\n",
        "    dataset = subset.dataset  # underlying NestedImageDataset\n",
        "    class_names = list(class_to_idx.keys())  # same mapping as during training\n",
        "\n",
        "    # Sample only from the subset indices\n",
        "    indices = random.sample(subset.indices, num_images)\n",
        "\n",
        "    for idx in indices:\n",
        "        img_path, true_label = dataset.samples[idx]\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        if transform:\n",
        "            img_tensor = transform(img).unsqueeze(0).to(device)  # add batch dimension\n",
        "        else:\n",
        "            img_tensor = transforms.ToTensor()(img).unsqueeze(0).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = model(img_tensor)\n",
        "            pred_label = torch.argmax(output, dim=1).item()\n",
        "\n",
        "        print(f'Image: {img_path.split(\"/\")[-1]}')\n",
        "        print(f'  True label:  {class_names[true_label]}')\n",
        "        print(f'  Predicted:   {class_names[pred_label]}')\n",
        "        print('-' * 40)\n",
        "\n",
        "\n",
        "classify_random_images(test_dataset, model, device, num_images=50, transform=transform_eval)\n"
      ],
      "metadata": {
        "id": "3SiLurE1Z0WL",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#------------\n",
        "#FRONT END\n",
        "#------------"
      ],
      "metadata": {
        "id": "hkO_J8wzleJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cancer_model.py\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "from torchvision.models import resnet50, ResNet50_Weights\n",
        "from PIL import Image\n",
        "\n",
        "BASE_DIR = Path(__file__).resolve().parent\n",
        "\n",
        "WEIGHTS_PATH = BASE_DIR / \"cancer_resnet50.pth\"\n",
        "CLASSES_PATH = BASE_DIR / \"classes.json\"\n",
        "\n",
        "with open(CLASSES_PATH, \"r\") as f:\n",
        "    CLASS_NAMES = json.load(f)\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def load_model():\n",
        "    model = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
        "    model.fc = nn.Linear(model.fc.in_features, 7)\n",
        "    state_dict = torch.load(WEIGHTS_PATH, map_location=DEVICE)\n",
        "    model.load_state_dict(state_dict)\n",
        "    model.to(DEVICE)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "MODEL = load_model()\n",
        "\n",
        "EVAL_TRANSFORM = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict(image: Image.Image):\n",
        "    if image.mode != \"RGB\":\n",
        "        image = image.convert(\"RGB\")\n",
        "\n",
        "    tensor = EVAL_TRANSFORM(image).unsqueeze(0).to(DEVICE)\n",
        "\n",
        "    logits = MODEL(tensor)\n",
        "    probs = torch.softmax(logits, dim=1)[0]\n",
        "\n",
        "    pred_idx = int(torch.argmax(probs).item())\n",
        "    pred_class = CLASS_NAMES[pred_idx]\n",
        "\n",
        "    probs_dict = {\n",
        "        CLASS_NAMES[i]: float(probs[i].item())\n",
        "        for i in range(len(CLASS_NAMES))\n",
        "    }\n",
        "\n",
        "    return pred_class, probs_dict"
      ],
      "metadata": {
        "id": "Ybt0bYx1mbz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# app.py (Flask version with inline HTML form)\n",
        "print(\"app.py importing...\")\n",
        "from flask import Flask, request\n",
        "from PIL import Image\n",
        "import io\n",
        "\n",
        "from cancer_model import predict\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route(\"/\", methods=[\"GET\"])\n",
        "def index():\n",
        "    # Direct HTML response â€“ no templates\n",
        "    return \"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "  <meta charset=\"UTF-8\">\n",
        "  <title>Cancer Classifier</title>\n",
        "</head>\n",
        "<body>\n",
        "  <h1>Cancer Image Classifier</h1>\n",
        "  <form action=\"/predict\" method=\"post\" enctype=\"multipart/form-data\">\n",
        "    <label for=\"image\">Select an image:</label>\n",
        "    <input type=\"file\" id=\"image\" name=\"image\" accept=\"image/*\" required>\n",
        "    <button type=\"submit\">Predict</button>\n",
        "  </form>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "@app.route(\"/predict\", methods=[\"POST\"])\n",
        "def predict_route():\n",
        "    file = request.files.get(\"image\")\n",
        "    if file is None or file.filename == \"\":\n",
        "        return \"No file selected\", 400\n",
        "\n",
        "    try:\n",
        "        contents = file.read()\n",
        "        image = Image.open(io.BytesIO(contents))\n",
        "\n",
        "        class_name, probs = predict(image)\n",
        "\n",
        "        # Sort probs descending for display\n",
        "        sorted_probs = sorted(probs.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        # Simple HTML result page\n",
        "        html = [\n",
        "            \"<h1>Prediction Result</h1>\",\n",
        "            f\"<h2>Prediction: {class_name}</h2>\",\n",
        "            \"<h3>Probabilities</h3>\",\n",
        "            \"<ul>\",\n",
        "        ]\n",
        "        for cls, p in sorted_probs:\n",
        "            html.append(f\"<li>{cls}: {p:.4f}</li>\")\n",
        "        html.append(\"</ul>\")\n",
        "        html.append('<a href=\"/\">Back</a>')\n",
        "\n",
        "        return \"\\n\".join(html)\n",
        "    except Exception as e:\n",
        "        return f\"Error: {e}\", 500\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.run(debug=True)"
      ],
      "metadata": {
        "id": "Z1aSNUxklfaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "import os\n",
        "\n",
        "# --- User settings ---\n",
        "GITHUB_USERNAME = \"NicholasPrice431\"\n",
        "GITHUB_REPO = \"CancerClassification\"\n",
        "GITHUB_EMAIL = \"nprice2021@fau.edu\"\n",
        "COMMIT_MSG = \"Add checkpoints and notebook\"\n",
        "FOLDER_TO_PUSH = \"/content/checkpoints\"\n",
        "NOTEBOOK_TO_PUSH = \"/content/4630_Final_005.ipynb\"\n",
        "RELATIVE_DATE = \"yesterday\"\n",
        "\n",
        "# --- Prompt for token ---\n",
        "GITHUB_PAT = getpass(\"Enter your GitHub Personal Access Token: \")\n",
        "\n",
        "# --- Configure git ---\n",
        "os.system(f\"git config --global user.name '{GITHUB_USERNAME}'\")\n",
        "os.system(f\"git config --global user.email '{GITHUB_EMAIL}'\")\n",
        "\n",
        "# --- Initialize repo ---\n",
        "os.chdir(\"/content\")\n",
        "if not os.path.exists(\".git\"):\n",
        "    print(\"Initializing git repo...\")\n",
        "    os.system(\"git init\")\n",
        "else:\n",
        "    print(\"Git repo already exists.\")\n",
        "\n",
        "# --- Add/update remote ---\n",
        "remotes = os.popen(\"git remote\").read().split()\n",
        "if \"origin\" in remotes:\n",
        "    print(\"Updating remote origin URL...\")\n",
        "    os.system(f\"git remote set-url origin https://{GITHUB_USERNAME}:{GITHUB_PAT}@github.com/{GITHUB_USERNAME}/{GITHUB_REPO}.git\")\n",
        "else:\n",
        "    print(\"Adding remote origin...\")\n",
        "    os.system(f\"git remote add origin https://{GITHUB_USERNAME}:{GITHUB_PAT}@github.com/{GITHUB_USERNAME}/{GITHUB_REPO}.git\")\n",
        "\n",
        "# --- Show git status ---\n",
        "print(\"\\nStatus before adding files:\")\n",
        "os.system(\"git status\")\n",
        "\n",
        "# --- Force add all .pt files and notebook ---\n",
        "os.system(f\"git add -f {FOLDER_TO_PUSH}/*.pt\")\n",
        "os.system(f\"git add -f {NOTEBOOK_TO_PUSH}\")\n",
        "\n",
        "print(\"\\nStatus after adding files:\")\n",
        "os.system(\"git status\")\n",
        "\n",
        "# --- Commit with explicit author and committer date ---\n",
        "print(\"\\nCommitting changes...\")\n",
        "os.system(\n",
        "    f'GIT_AUTHOR_DATE=\"{RELATIVE_DATE}\" GIT_COMMITTER_DATE=\"{RELATIVE_DATE}\" '\n",
        "    f'git commit --allow-empty -m \"{COMMIT_MSG}\"'\n",
        ")\n",
        "\n",
        "print(\"\\nLast commit info:\")\n",
        "os.system(\"git log -1 --pretty=full\")\n",
        "\n",
        "# --- Push to GitHub ---\n",
        "print(\"\\nPushing to GitHub...\")\n",
        "os.system(\"git branch -M main\")\n",
        "os.system(f\"git push -u https://{GITHUB_USERNAME}:{GITHUB_PAT}@github.com/{GITHUB_USERNAME}/{GITHUB_REPO}.git main\")\n"
      ],
      "metadata": {
        "id": "rrX6IoSv4Tmz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}