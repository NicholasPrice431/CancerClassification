{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2QELq5Ig6MoT",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "import os\n",
        "import shutil\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader, random_split, Dataset\n",
        "from torchvision import datasets, models, transforms\n",
        "import torch.optim as optim\n",
        "from torchvision.models import resnet50, ResNet50_Weights\n",
        "from tqdm import tqdm\n",
        "from collections import Counter\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import shutil\n",
        "import getpass\n",
        "import nbformat\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import random\n",
        "from PIL import Image\n",
        "from sklearn.metrics import accuracy_score, classification_report\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Download latest version of the dataset\n",
        "path = kagglehub.dataset_download('obulisainaren/multi-cancer')\n",
        "\n",
        "print('Path to dataset files:', path)"
      ],
      "metadata": {
        "id": "_kJynV8K-8WG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Path check\n",
        "dataset_path = os.path.join(path, 'Multi Cancer', 'Multi Cancer')\n",
        "print('Using dataset_path:', dataset_path)\n",
        "print(os.listdir(dataset_path))\n"
      ],
      "metadata": {
        "id": "stffdth1u1VI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Download ResNet50 model\n",
        "model = resnet50(weights=ResNet50_Weights.DEFAULT)"
      ],
      "metadata": {
        "id": "ayvIiEL3URGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Paths and device check\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "if device.type == 'cuda':\n",
        "    print('GPU:', torch.cuda.get_device_name(0))\n",
        "    print('Total GPU memory:', round(torch.cuda.get_device_properties(0).total_memory / 1e9, 2), 'GB')\n",
        "\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "transform_eval = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "\n",
        "# Collect all subfolders as classes\n",
        "all_subfolders = []\n",
        "for main_class in os.listdir(dataset_path):\n",
        "    main_path = os.path.join(dataset_path, main_class)\n",
        "    if os.path.isdir(main_path):\n",
        "        for sub_class in os.listdir(main_path):\n",
        "            sub_path = os.path.join(main_path, sub_class)\n",
        "            if os.path.isdir(sub_path):\n",
        "                all_subfolders.append(sub_path)\n",
        "\n",
        "# ap subfolder paths to class indices and create samples list\n",
        "samples = []\n",
        "class_to_idx = {}\n",
        "for idx, subfolder_path in enumerate(all_subfolders):\n",
        "    class_name = os.path.basename(subfolder_path)\n",
        "    class_to_idx[class_name] = idx\n",
        "    for fname in os.listdir(subfolder_path):\n",
        "        if fname.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "            samples.append((os.path.join(subfolder_path, fname), idx))\n",
        "\n",
        "print('Detected classes:', list(class_to_idx.keys()))\n",
        "print('Total images:', len(samples))\n",
        "\n",
        "\n",
        "#Dataset to deal with nested folders\n",
        "class NestedImageDataset(Dataset):\n",
        "    def __init__(self, samples, transform=None):\n",
        "        self.samples = samples\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path, label = self.samples[idx]\n",
        "        image = Image.open(path).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "full_dataset = NestedImageDataset(samples, transform=transform_train)\n",
        "\n",
        "#Train/Test/Val Split\n",
        "total_size = len(full_dataset)\n",
        "test_size = int(0.1 * total_size)\n",
        "val_size = int(0.1 * total_size)\n",
        "train_size = total_size - val_size - test_size\n",
        "\n",
        "generator = torch.Generator().manual_seed(42)\n",
        "train_dataset, val_dataset, test_dataset = random_split(\n",
        "    full_dataset, [train_size, val_size, test_size], generator=generator\n",
        ")\n",
        "\n",
        "#Evaluation transforms\n",
        "val_dataset.dataset.transform = transform_eval\n",
        "test_dataset.dataset.transform = transform_eval\n",
        "\n",
        "print(f'Train size: {len(train_dataset)}, Val size: {len(val_dataset)}, Test size: {len(test_dataset)}')\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=4, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4, pin_memory=True)\n",
        "\n",
        "\n",
        "model = resnet50(weights=ResNet50_Weights.DEFAULT)        #Model\n",
        "num_classes = len(class_to_idx)\n",
        "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "\n",
        "#Training\n",
        "epochs = 25\n",
        "best_val_acc = 0.0\n",
        "checkpoint_dir = '/content/checkpoints'\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs} [Training]', leave=False)\n",
        "\n",
        "    for images, labels in pbar:\n",
        "        images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        with torch.cuda.amp.autocast():\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        pbar.set_postfix({'Batch Loss': loss.item(),\n",
        "                          'GPU Mem (GB)': round(torch.cuda.memory_allocated(0)/1e9, 2)})\n",
        "\n",
        "\n",
        "    #Validation\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
        "            with torch.cuda.amp.autocast():\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "                _, predicted = outputs.max(1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "    val_acc = 100 * correct / total\n",
        "    print(f'\\nEpoch {epoch+1}/{epochs} Summary:')\n",
        "    print(f'  Train Loss: {total_loss/len(train_loader):.4f}')\n",
        "    print(f'  Val Loss:   {val_loss/len(val_loader):.4f}')\n",
        "    print(f'  Val Acc:    {val_acc:.2f}%')\n",
        "\n",
        "    #Saves checkpoints if they improve\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        checkpoint_path = os.path.join(checkpoint_dir, f'best_model_epoch{epoch+1}.pt')\n",
        "        torch.save(model.state_dict(), checkpoint_path)\n",
        "        print(f'  New best: {checkpoint_path}')\n",
        "\n",
        "    if device.type == 'cuda':\n",
        "        print(f'  GPU Memory Allocated: {round(torch.cuda.memory_allocated(0)/1e9,2)} GB')\n",
        "        print(f'  GPU Memory Cached:    {round(torch.cuda.memory_reserved(0)/1e9,2)} GB')\n",
        "    print('='*50)\n",
        "\n",
        "print('Training complete.')\n",
        "\n",
        "#Test Evaluation\n",
        "print('\\nEvaluating on full test set...')\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for images, labels in tqdm(test_loader, desc='Testing'):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        with torch.cuda.amp.autocast():\n",
        "            outputs = model(images)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Per-class metrics\n",
        "print('\\nPer-class metrics:')\n",
        "print(classification_report(all_labels, all_preds, target_names=list(class_to_idx.keys())))\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "print('\\nConfusion Matrix:\\n', cm)"
      ],
      "metadata": {
        "id": "bqAmd4E24-h0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Initialization (For if you'd like to try this out yourself the model best_model_epoch5.pt in the repo)\n",
        "#Only run this code if you DON'T want to train your own model and would rather use the pretrained model\n",
        "\n",
        "#Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#Model Initialization\n",
        "num_classes = 26  # number of classes in your trained model\n",
        "model = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
        "model.fc = nn.Linear(model.fc.in_features, num_classes)  # number of classes\n",
        "model = model.to(device)\n",
        "\n",
        "#Load trained weights\n",
        "BEST_MODEL = \"/content/checkpoints/best_model_epoch5.pt\"  # Download the model from the repo and paste the path here\n",
        "model.load_state_dict(torch.load(BEST_MODEL, map_location=device))\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "h7Fl-sNMBIlM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()  # ensure evaluation mode\n",
        "\n",
        "all_labels = []\n",
        "all_preds = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in val_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        with torch.cuda.amp.autocast():\n",
        "            outputs = model(images)\n",
        "            _, predicted = outputs.max(1)\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "        all_preds.extend(predicted.cpu().numpy())\n",
        "\n",
        "# Overall accuracy\n",
        "overall_acc = accuracy_score(all_labels, all_preds)\n",
        "print(f'Overall Accuracy: {overall_acc*100:.2f}%\\n')\n",
        "\n",
        "# Per-class precision, recall, F1-score\n",
        "print('Per-class metrics:\\n')\n",
        "target_names = list(class_to_idx.keys())  # ensure correct class names\n",
        "print(classification_report(\n",
        "    all_labels, all_preds,\n",
        "    target_names=target_names,\n",
        "    digits=4  # show 4 decimal places\n",
        "))"
      ],
      "metadata": {
        "id": "9aGWw3iNHosk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Ensure the model is in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "all_labels = []\n",
        "all_preds = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in val_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        with torch.cuda.amp.autocast():\n",
        "            outputs = model(images)\n",
        "            _, predicted = outputs.max(1)\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "        all_preds.extend(predicted.cpu().numpy())\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]  # normalize\n",
        "\n",
        "# Plot matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Blues',\n",
        "            xticklabels=list(class_to_idx.keys()),\n",
        "            yticklabels=list(class_to_idx.keys()))\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Normalized Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NeMvC10zHw-5",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_random_images(subset, model, device, num_images=20, transform=None):    #Randomly chooses 20 images from a dataset and classifies them (proof of concept)\n",
        "\n",
        "    import random\n",
        "    from PIL import Image\n",
        "    from torchvision import transforms\n",
        "\n",
        "    model.eval()\n",
        "    dataset = subset.dataset  # underlying NestedImageDataset\n",
        "    class_names = list(class_to_idx.keys())  # same mapping as during training\n",
        "\n",
        "    # Sample only from the subset indices\n",
        "    indices = random.sample(subset.indices, num_images)\n",
        "\n",
        "    for idx in indices:\n",
        "        img_path, true_label = dataset.samples[idx]\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        if transform:\n",
        "            img_tensor = transform(img).unsqueeze(0).to(device)  # add batch dimension\n",
        "        else:\n",
        "            img_tensor = transforms.ToTensor()(img).unsqueeze(0).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = model(img_tensor)\n",
        "            pred_label = torch.argmax(output, dim=1).item()\n",
        "\n",
        "        print(f'Image: {img_path.split(\"/\")[-1]}')\n",
        "        print(f'  True label:  {class_names[true_label]}')\n",
        "        print(f'  Predicted:   {class_names[pred_label]}')\n",
        "        print('-' * 40)\n",
        "\n",
        "\n",
        "classify_random_images(test_dataset, model, device, num_images=50, transform=transform_eval)\n"
      ],
      "metadata": {
        "id": "3SiLurE1Z0WL",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b81bd983-51f1-4d99-9c47-01b6387c2abe"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: oral_normal_0862.jpg\n",
            "  True label:  oral_normal\n",
            "  Predicted:   oral_normal\n",
            "----------------------------------------\n",
            "Image: lymph_fl_2869.jpg\n",
            "  True label:  lymph_fl\n",
            "  Predicted:   lymph_fl\n",
            "----------------------------------------\n",
            "Image: breast_benign_1539.jpg\n",
            "  True label:  breast_benign\n",
            "  Predicted:   breast_benign\n",
            "----------------------------------------\n",
            "Image: lymph_fl_1399.jpg\n",
            "  True label:  lymph_fl\n",
            "  Predicted:   lymph_fl\n",
            "----------------------------------------\n",
            "Image: breast_malignant_1523.jpg\n",
            "  True label:  breast_malignant\n",
            "  Predicted:   breast_malignant\n",
            "----------------------------------------\n",
            "Image: brain_menin_1860.jpg\n",
            "  True label:  brain_menin\n",
            "  Predicted:   brain_menin\n",
            "----------------------------------------\n",
            "Image: oral_scc_2919.jpg\n",
            "  True label:  oral_scc\n",
            "  Predicted:   oral_scc\n",
            "----------------------------------------\n",
            "Image: brain_glioma_2804.jpg\n",
            "  True label:  brain_glioma\n",
            "  Predicted:   brain_glioma\n",
            "----------------------------------------\n",
            "Image: lymph_cll_2581.jpg\n",
            "  True label:  lymph_cll\n",
            "  Predicted:   lymph_cll\n",
            "----------------------------------------\n",
            "Image: lung_bnt_4898.jpg\n",
            "  True label:  lung_bnt\n",
            "  Predicted:   lung_bnt\n",
            "----------------------------------------\n",
            "Image: cervix_dyk_1174.jpg\n",
            "  True label:  cervix_dyk\n",
            "  Predicted:   cervix_dyk\n",
            "----------------------------------------\n",
            "Image: all_benign_3879.jpg\n",
            "  True label:  all_benign\n",
            "  Predicted:   all_benign\n",
            "----------------------------------------\n",
            "Image: lymph_cll_1276.jpg\n",
            "  True label:  lymph_cll\n",
            "  Predicted:   lymph_cll\n",
            "----------------------------------------\n",
            "Image: cervix_koc_3331.jpg\n",
            "  True label:  cervix_koc\n",
            "  Predicted:   cervix_koc\n",
            "----------------------------------------\n",
            "Image: lung_aca_0500.jpg\n",
            "  True label:  lung_aca\n",
            "  Predicted:   lung_aca\n",
            "----------------------------------------\n",
            "Image: breast_benign_1386.jpg\n",
            "  True label:  breast_benign\n",
            "  Predicted:   breast_benign\n",
            "----------------------------------------\n",
            "Image: kidney_normal_1879.jpg\n",
            "  True label:  kidney_normal\n",
            "  Predicted:   kidney_normal\n",
            "----------------------------------------\n",
            "Image: cervix_mep_3867.jpg\n",
            "  True label:  cervix_mep\n",
            "  Predicted:   cervix_mep\n",
            "----------------------------------------\n",
            "Image: kidney_tumor_0581.jpg\n",
            "  True label:  kidney_tumor\n",
            "  Predicted:   kidney_tumor\n",
            "----------------------------------------\n",
            "Image: colon_bnt_3830.jpg\n",
            "  True label:  colon_bnt\n",
            "  Predicted:   colon_bnt\n",
            "----------------------------------------\n",
            "Image: cervix_mep_4977.jpg\n",
            "  True label:  cervix_mep\n",
            "  Predicted:   cervix_mep\n",
            "----------------------------------------\n",
            "Image: breast_malignant_1899.jpg\n",
            "  True label:  breast_malignant\n",
            "  Predicted:   breast_malignant\n",
            "----------------------------------------\n",
            "Image: lung_bnt_3139.jpg\n",
            "  True label:  lung_bnt\n",
            "  Predicted:   lung_bnt\n",
            "----------------------------------------\n",
            "Image: oral_scc_0102.jpg\n",
            "  True label:  oral_scc\n",
            "  Predicted:   oral_scc\n",
            "----------------------------------------\n",
            "Image: cervix_dyk_3458.jpg\n",
            "  True label:  cervix_dyk\n",
            "  Predicted:   cervix_dyk\n",
            "----------------------------------------\n",
            "Image: kidney_tumor_2835.jpg\n",
            "  True label:  kidney_tumor\n",
            "  Predicted:   kidney_tumor\n",
            "----------------------------------------\n",
            "Image: brain_tumor_2510.jpg\n",
            "  True label:  brain_tumor\n",
            "  Predicted:   brain_tumor\n",
            "----------------------------------------\n",
            "Image: brain_glioma_3197.jpg\n",
            "  True label:  brain_glioma\n",
            "  Predicted:   brain_glioma\n",
            "----------------------------------------\n",
            "Image: lymph_cll_1496.jpg\n",
            "  True label:  lymph_cll\n",
            "  Predicted:   lymph_cll\n",
            "----------------------------------------\n",
            "Image: cervix_sfi_0705.jpg\n",
            "  True label:  cervix_sfi\n",
            "  Predicted:   cervix_sfi\n",
            "----------------------------------------\n",
            "Image: brain_glioma_4796.jpg\n",
            "  True label:  brain_glioma\n",
            "  Predicted:   brain_glioma\n",
            "----------------------------------------\n",
            "Image: colon_aca_3449.jpg\n",
            "  True label:  colon_aca\n",
            "  Predicted:   colon_aca\n",
            "----------------------------------------\n",
            "Image: kidney_tumor_1915.jpg\n",
            "  True label:  kidney_tumor\n",
            "  Predicted:   kidney_tumor\n",
            "----------------------------------------\n",
            "Image: brain_glioma_1948.jpg\n",
            "  True label:  brain_glioma\n",
            "  Predicted:   brain_glioma\n",
            "----------------------------------------\n",
            "Image: brain_glioma_0911.jpg\n",
            "  True label:  brain_glioma\n",
            "  Predicted:   brain_glioma\n",
            "----------------------------------------\n",
            "Image: lymph_mcl_3330.jpg\n",
            "  True label:  lymph_mcl\n",
            "  Predicted:   lymph_mcl\n",
            "----------------------------------------\n",
            "Image: all_early_2801.jpg\n",
            "  True label:  all_early\n",
            "  Predicted:   all_early\n",
            "----------------------------------------\n",
            "Image: breast_benign_0682.jpg\n",
            "  True label:  breast_benign\n",
            "  Predicted:   breast_benign\n",
            "----------------------------------------\n",
            "Image: breast_benign_1643.jpg\n",
            "  True label:  breast_benign\n",
            "  Predicted:   breast_benign\n",
            "----------------------------------------\n",
            "Image: cervix_dyk_0286.jpg\n",
            "  True label:  cervix_dyk\n",
            "  Predicted:   cervix_dyk\n",
            "----------------------------------------\n",
            "Image: lymph_cll_3150.jpg\n",
            "  True label:  lymph_cll\n",
            "  Predicted:   lymph_cll\n",
            "----------------------------------------\n",
            "Image: lymph_cll_4785.jpg\n",
            "  True label:  lymph_cll\n",
            "  Predicted:   lymph_cll\n",
            "----------------------------------------\n",
            "Image: cervix_sfi_4676.jpg\n",
            "  True label:  cervix_sfi\n",
            "  Predicted:   cervix_sfi\n",
            "----------------------------------------\n",
            "Image: lymph_fl_2103.jpg\n",
            "  True label:  lymph_fl\n",
            "  Predicted:   lymph_fl\n",
            "----------------------------------------\n",
            "Image: lung_aca_3109.jpg\n",
            "  True label:  lung_aca\n",
            "  Predicted:   lung_aca\n",
            "----------------------------------------\n",
            "Image: cervix_koc_4466.jpg\n",
            "  True label:  cervix_koc\n",
            "  Predicted:   cervix_koc\n",
            "----------------------------------------\n",
            "Image: all_early_3572.jpg\n",
            "  True label:  all_early\n",
            "  Predicted:   all_early\n",
            "----------------------------------------\n",
            "Image: breast_benign_2664.jpg\n",
            "  True label:  breast_benign\n",
            "  Predicted:   breast_benign\n",
            "----------------------------------------\n",
            "Image: lymph_cll_2538.jpg\n",
            "  True label:  lymph_cll\n",
            "  Predicted:   lymph_cll\n",
            "----------------------------------------\n",
            "Image: colon_aca_3953.jpg\n",
            "  True label:  colon_aca\n",
            "  Predicted:   colon_aca\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#------------\n",
        "#FRONT END\n",
        "#------------"
      ],
      "metadata": {
        "id": "hkO_J8wzleJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cancer model.py\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "from torchvision.models import resnet50, ResNet50_Weights\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "BASE_DIR = Path(file).resolve().parent\n",
        "\n",
        "\n",
        "WEIGHTS_PATH = BASE_DIR / \"best_model_epoch5.pt\"\n",
        "CLASSES_PATH = BASE_DIR / \"classes.json\"\n",
        "\n",
        "\n",
        "with open(CLASSES_PATH, \"r\") as f:\n",
        "    CLASS_NAMES = json.load(f)\n",
        "\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "def load_model():\n",
        "\n",
        "    model = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
        "    model.fc = nn.Linear(model.fc.in_features, 26)\n",
        "\n",
        "\n",
        "    state_dict = torch.load(WEIGHTS_PATH, map_location=DEVICE)\n",
        "    model.load_state_dict(state_dict)\n",
        "\n",
        "    model.to(DEVICE)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "MODEL = load_model()\n",
        "\n",
        "\n",
        "EVAL_TRANSFORM = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict(image: Image.Image):\n",
        "    # Ensure 3-channel RGB\n",
        "    if image.mode != \"RGB\":\n",
        "        image = image.convert(\"RGB\")\n",
        "\n",
        "    # Preprocess and move to device\n",
        "    tensor = EVAL_TRANSFORM(image).unsqueeze(0).to(DEVICE)\n",
        "\n",
        "    # Forward pass\n",
        "    logits = MODEL(tensor)\n",
        "    probs = torch.softmax(logits, dim=1)[0]\n",
        "\n",
        "    # Top-1 prediction\n",
        "    pred_idx = int(torch.argmax(probs).item())\n",
        "    pred_class = CLASS_NAMES[pred_idx]\n",
        "\n",
        "    # Full probability map\n",
        "    probs_dict = {\n",
        "        CLASS_NAMES[i]: float(probs[i].item())\n",
        "        for i in range(len(CLASS_NAMES))\n",
        "    }\n",
        "\n",
        "    return pred_class, probs_dict"
      ],
      "metadata": {
        "id": "Ybt0bYx1mbz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#app.py\n",
        "print(\"app.py importing...\")\n",
        "from flask import Flask, request\n",
        "from PIL import Image\n",
        "import io\n",
        "\n",
        "from cancer_model import predict\n",
        "\n",
        "app = Flask(name)\n",
        "\n",
        "@app.route(\"/\", methods=[\"GET\"])\n",
        "def index():\n",
        "    return \"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "  <title>Cancer Classifier</title>\n",
        "</head>\n",
        "<body>\n",
        "  <h1>Cancer Classifier</h1>\n",
        "  <h2>Cancer Image Classifier</h2>\n",
        "\n",
        "  <form action=\"/predict\" method=\"post\" enctype=\"multipart/form-data\">\n",
        "    <p>Select an image:</p>\n",
        "    <input type=\"file\" name=\"image\" accept=\"image/*\" required>\n",
        "    <br><br>\n",
        "    <button type=\"submit\">Upload and Classify</button>\n",
        "  </form>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "@app.route(\"/predict\", methods=[\"POST\"])\n",
        "def predict_route():\n",
        "    file = request.files.get(\"image\")\n",
        "    if file is None or file.filename == \"\":\n",
        "        return \"No file selected\", 400\n",
        "\n",
        "    try:\n",
        "        contents = file.read()\n",
        "        image = Image.open(io.BytesIO(contents))\n",
        "\n",
        "        class_name, probs = predict(image)\n",
        "\n",
        "        # Sort probs descending for display\n",
        "        sorted_probs = sorted(probs.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        # Build HTML result page\n",
        "        html = []\n",
        "        html.append(\"<h1>Prediction Result</h1>\")\n",
        "        html.append(f\"<h2>Top prediction: {class_name}</h2>\")\n",
        "\n",
        "        html.append(\"<h3>All subclass probabilities</h3>\")\n",
        "        html.append(\"<ul>\")\n",
        "        for cls, p in sorted_probs:\n",
        "            html.append(f\"<li>{cls}: {p:.4f}</li>\")\n",
        "        html.append(\"</ul>\")\n",
        "\n",
        "        html.append('<p><a href=\"/\">Back</a></p>')\n",
        "\n",
        "        return \"\\n\".join(html)\n",
        "    except Exception as e:\n",
        "        return f\"Error: {e}\", 500\n",
        "\n",
        "\n",
        "if name == \"main\":\n",
        "    app.run(debug=True)"
      ],
      "metadata": {
        "id": "Z1aSNUxklfaL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}